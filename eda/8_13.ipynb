{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "not_replace = True\n",
    "\n",
    "def get_app_desc(**params):\n",
    "    \"\"\"\n",
    "    返回 app_desc 文件内容\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    app_desc_data = pd.read_csv('/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/original/app_desc.dat', header=None, encoding='utf8', delimiter=' ')\n",
    "    # 以tab键分割，不知道为啥delimiter='\\t'会报错，所以先读入再分割。\n",
    "    app_desc_data = pd.DataFrame(app_desc_data[0].apply(lambda x: x.split('\\t')).tolist(), columns=['id', 'conment'])\n",
    "\n",
    "    return app_desc_data\n",
    "\n",
    "\n",
    "def get_apptype_id_name(**params):\n",
    "    \"\"\"\n",
    "    返回 apptype_id_name 文件内容\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    apptype_id_name_path = '/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/original/apptype_id_name.txt'\n",
    "    apptype_id_name_data = pd.read_table(apptype_id_name_path, header=None, sep='\\t', names=['label_code', 'label'])\n",
    "\n",
    "    return apptype_id_name_data\n",
    "\n",
    "\n",
    "def get_apptype_train(**params):\n",
    "    \"\"\"\n",
    "    返回 apptype_train 文件内容\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    apptype_train_data = pd.read_csv('/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/original/apptype_train.dat', header=None, encoding='utf8', delimiter=' ')\n",
    "    # 以tab键分割，不知道为啥delimiter='\\t'会报错，所以先读入再分割。\n",
    "    apptype_train_data = pd.DataFrame(apptype_train_data[0].apply(lambda x: x.split('\\t')).tolist(), columns=['id', 'label', 'conment'])\n",
    "\n",
    "    return apptype_train_data\n",
    "\n",
    "\n",
    "def get_app_desc_apptype(app_desc, apptype_id_name, save=True, **params):\n",
    "    \"\"\"\n",
    "    预判断app_desc的label, 根据apptype_id_name中的label是否存在于conment中，来标注label_id\n",
    "    :param app_desc:\n",
    "    :param apptype_id_name:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    if os.path.exists('/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/cache/app_desc_apptype.h5') and not_replace:\n",
    "        app_desc = reduce_mem_usage(\n",
    "            pd.read_hdf(path_or_buf='/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/cache/app_desc_apptype.h5', mode='r', key='app_desc_apptype'))\n",
    "    else:\n",
    "        index = 0\n",
    "        for i in range(apptype_id_name.shape[0]):\n",
    "            if len(str(apptype_id_name.iloc[i, 0])) < 6:\n",
    "                continue\n",
    "            else:\n",
    "                index = i\n",
    "                break\n",
    "\n",
    "        result = []\n",
    "        for raw_app_desc in range(app_desc.shape[0]):\n",
    "            if raw_app_desc % 10000 == 1:\n",
    "                print(raw_app_desc)\n",
    "\n",
    "            counts_dict = {}\n",
    "            for raw_apptype_id_name in range(index, apptype_id_name.shape[0]):\n",
    "                # 父字符串\n",
    "                father = app_desc.iloc[raw_app_desc, 1]\n",
    "                # 子字符串\n",
    "                son = apptype_id_name.iloc[raw_apptype_id_name, 1]\n",
    "                # 出现次数\n",
    "                counts = father.count(son)\n",
    "                # 如果出现次数大于等于8次， 则记录\n",
    "                if counts >= 8:\n",
    "                    counts_dict[str(apptype_id_name.iloc[raw_apptype_id_name, 0])] = counts\n",
    "\n",
    "            counts_dict_sorted = sorted(counts_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "            result.append([i[0] for i in counts_dict_sorted])\n",
    "\n",
    "        app_desc['label'] = result\n",
    "\n",
    "        if save:\n",
    "            app_desc.to_hdf(path_or_buf='/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/cache/app_desc_apptype.h5', key='app_desc_apptype')\n",
    "\n",
    "    return app_desc\n",
    "\n",
    "\n",
    "def get_stopwords(**params):\n",
    "    \"\"\"\n",
    "    获取停用词文件数据\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open('/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/stopwords/stopwords.txt', 'r') as file:\n",
    "        return file.readlines()\n",
    "\n",
    "\n",
    "def get_label1_label2(df, **params):\n",
    "    \"\"\"\n",
    "    构造label1和label2 特征\n",
    "    :param df:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df['label1'] = df['label'].apply(lambda x: x.split('|')[0])\n",
    "    df['label2'] = df['label'].apply(lambda x: x.split('|')[1] if '|' in x else 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_counts_less_than_k(df, k, **params):\n",
    "    \"\"\"\n",
    "    删除出现次数少于k次的 数据\n",
    "    :param df:\n",
    "    :param k:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    counts_less_than_k = []\n",
    "\n",
    "    for key, value in df['label1'].value_counts().items():\n",
    "        if value < k:\n",
    "            counts_less_than_k.append(key)\n",
    "\n",
    "    df = df[~df['label1'].isin(counts_less_than_k)].reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    减少内存消耗\n",
    "    :param df:\n",
    "    :param verbose:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (\n",
    "            start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def store_sparse_mat(M, name, filename='store.h5'):\n",
    "    \"\"\"\n",
    "    Store a csr matrix in HDF5\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : scipy.sparse.csr.csr_matrix\n",
    "     sparse matrix to be stored\n",
    "\n",
    "    name: str\n",
    "     node prefix in HDF5 hierarchy\n",
    "\n",
    "    filename: str\n",
    "     HDF5 filename\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy import sparse\n",
    "    import tables\n",
    "\n",
    "    assert (M.__class__ == sparse.csr.csr_matrix), 'M must be a csr matrix'\n",
    "    with tables.open_file(filename, 'a') as f:\n",
    "        for attribute in ('data', 'indices', 'indptr', 'shape'):\n",
    "            full_name = f'{name}_{attribute}'\n",
    "\n",
    "            # remove existing nodes\n",
    "            try:\n",
    "                n = getattr(f.root, full_name)\n",
    "                n._f_remove()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "                # add nodes\n",
    "            arr = np.array(getattr(M, attribute))\n",
    "            atom = tables.Atom.from_dtype(arr.dtype)\n",
    "            ds = f.create_carray(f.root, full_name, atom, arr.shape)\n",
    "            ds[:] = arr\n",
    "\n",
    "\n",
    "def load_sparse_mat(name, filename='store.h5'):\n",
    "    \"\"\"\n",
    "    Load a csr matrix from HDF5\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str\n",
    "     node prefix in HDF5 hierarchy\n",
    "\n",
    "    filename: str\n",
    "     HDF5 filename\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    M : scipy.sparse.csr.csr_matrix\n",
    "     loaded sparse matrix\n",
    "    \"\"\"\n",
    "    from scipy import sparse\n",
    "    import tables\n",
    "\n",
    "    with tables.open_file(filename) as f:\n",
    "        # get nodes\n",
    "        attributes = []\n",
    "        for attribute in ('data', 'indices', 'indptr', 'shape'):\n",
    "            attributes.append(getattr(f.root, f'{name}_{attribute}').read())\n",
    "            # construct sparse matrix\n",
    "    M = sparse.csr_matrix(tuple(attributes[:3]), shape=attributes[3])\n",
    "    return M\n",
    "\n",
    "\n",
    "def get_term_doc(apptype_train, app_desc, save=True, **params):\n",
    "    \"\"\"\n",
    "    获取train/test TF-IDF矩阵\n",
    "    :param df:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import jieba\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    apptype_train_term_doc_path = '/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/cache/apptype_train_term_doc.h5'\n",
    "    app_desc_term_doc_path = '/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/cache/app_desc_term_doc.h5'\n",
    "\n",
    "    if os.path.exists(apptype_train_term_doc_path) and os.path.exists(app_desc_term_doc_path) and not_replace:\n",
    "        apptype_train_term_doc = load_sparse_mat(name='apptype_train_term_doc', filename=apptype_train_term_doc_path)\n",
    "        app_desc_term_doc = load_sparse_mat(name='app_desc_term_doc', filename=app_desc_term_doc_path)\n",
    "    else:\n",
    "        stopwords = get_stopwords()\n",
    "\n",
    "        print('stopwords length:', len(stopwords))\n",
    "        apptype_train['conment'] = apptype_train['conment'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "        app_desc['conment'] = app_desc['conment'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "\n",
    "        vec = TfidfVectorizer(ngram_range=(1, 1), min_df=5, max_df=0.8, use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "                              stop_words=stopwords)  # 这里参数可以改\n",
    "        apptype_train_term_doc = vec.fit_transform(apptype_train['conment'])\n",
    "        app_desc_term_doc = vec.transform(app_desc['conment'])\n",
    "\n",
    "        print(type(apptype_train_term_doc))\n",
    "        if save:\n",
    "            store_sparse_mat(M=apptype_train_term_doc, name='apptype_train_term_doc',\n",
    "                             filename=apptype_train_term_doc_path)\n",
    "            store_sparse_mat(M=app_desc_term_doc, name='app_desc_term_doc', filename=app_desc_term_doc_path)\n",
    "\n",
    "    return apptype_train, app_desc, apptype_train_term_doc, app_desc_term_doc\n",
    "\n",
    "\n",
    "def get_label_encoder(apptype_train, columns: list = None, **params):\n",
    "    \"\"\"\n",
    "    返回经过labelEncoder后的数据\n",
    "    :param apptype_train:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    lbl = None\n",
    "    for column in columns:\n",
    "        # 构造标签属性\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "\n",
    "        # 训练\n",
    "        lbl.fit(apptype_train[column].values)\n",
    "        apptype_train[column] = lbl.transform(apptype_train[column].values)\n",
    "\n",
    "    return apptype_train, lbl\n",
    "\n",
    "\n",
    "def cross_validation(apptype_train, app_desc, apptype_train_term_doc, app_desc_term_doc, **params):\n",
    "    \"\"\"\n",
    "    k折交叉验证\n",
    "    :param apptype_train:\n",
    "    :param app_desc:\n",
    "    :param apptype_train_term_doc:\n",
    "    :param app_desc_term_doc:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.linear_model import RidgeClassifier\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # 类别数 122\n",
    "    num_class = apptype_train['label1'].max() + 1\n",
    "    # 类别\n",
    "    label = apptype_train['label1']\n",
    "\n",
    "    n_splits = 5\n",
    "    stack_train = np.zeros((apptype_train.shape[0], num_class))\n",
    "    stack_test = np.zeros((app_desc.shape[0], num_class))\n",
    "    \n",
    "    select_model = RidgeClassifier(normalize=True, max_iter=1000, random_state=2019)\n",
    "    for i, (tr, va) in enumerate(\n",
    "            StratifiedKFold(n_splits=n_splits, random_state=2019).split(apptype_train_term_doc, label)):\n",
    "        print('stack:%d/%d' % ((i + 1), n_splits))\n",
    "        start = time.clock()\n",
    "\n",
    "        model = select_model.fit(apptype_train_term_doc[tr], label[tr])\n",
    "        score_va = model._predict_proba_lr(apptype_train_term_doc[va])\n",
    "        score_te = model._predict_proba_lr(app_desc_term_doc)\n",
    "\n",
    "        stack_train[va] += score_va\n",
    "        stack_test += score_te\n",
    "        print('consuming time:', time.clock() - start)\n",
    "\n",
    "    print(\"model acc_score:\",\n",
    "          metrics.accuracy_score(label, np.argmax(stack_train, axis=1), normalize=True, sample_weight=None))\n",
    "\n",
    "    return stack_train, stack_test\n",
    "\n",
    "\n",
    "def get_offline_accuracy(apptype_train, app_desc, stack_train, stack_test, lbl, **params):\n",
    "    \"\"\"\n",
    "    返回线下准确率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    label = apptype_train['label1']\n",
    "\n",
    "    # 获取第一第二个标签：取概率最大的前两个即可：\n",
    "    m = pd.DataFrame(stack_train)\n",
    "    first = []\n",
    "    second = []\n",
    "    for j, row in m.iterrows():\n",
    "        zz = list(np.argsort(row))\n",
    "        # 第一个标签\n",
    "        first.append(row.index[zz[-1]])\n",
    "        # 第二个标签\n",
    "        second.append(row.index[zz[-2]])\n",
    "        \n",
    "    m['label1'] = first\n",
    "    m['label2'] = second\n",
    "\n",
    "    # 计算准确率，只要命中一个就算正确：\n",
    "    k = 0\n",
    "    for i in range(len(label)):\n",
    "        if label[i] in [m.loc[i, 'label1'], m.loc[i, 'label2']]:\n",
    "            k += 1\n",
    "        else:\n",
    "            pass\n",
    "    print('线下准确率：%f' % (k / len(label)))\n",
    "\n",
    "    # 准备测试集结果：\n",
    "    results = pd.DataFrame(stack_test)\n",
    "    first = []\n",
    "    second = []\n",
    "    for j, row in results.iterrows():\n",
    "        zz = list(np.argsort(row))\n",
    "        \n",
    "        # 第一个标签\n",
    "        first.append(row.index[zz[-1]])\n",
    "        # 第二个标签\n",
    "        second.append(row.index[zz[-2]])\n",
    "\n",
    "    results['label1'] = first\n",
    "    results['label2'] = second\n",
    "\n",
    "    print(\"len(list(train['label1'].values): \", len(list(apptype_train['label1'].values)))\n",
    "    print(results.head())\n",
    "\n",
    "    # 之前编码，最后逆编码回来：\n",
    "    results['label1'] = lbl.inverse_transform(results['label1'].apply(lambda x: int(x)).values)\n",
    "    results['label2'] = lbl.inverse_transform(results['label2'].apply(lambda x: int(x)).values)\n",
    "\n",
    "    import time\n",
    "    start = time.clock()\n",
    "\n",
    "    ####################未结合与判断\n",
    "    app_desc['label1'] = results['label1']\n",
    "    app_desc['label2'] = results['label2']\n",
    "    \n",
    "    print(time.clock() - start)\n",
    "\n",
    "    pd.concat([app_desc[['id', 'label1', 'label2']]], axis=1).to_csv(\n",
    "        '/home/wjunneng/Python/2019-Iflytek-Big-Data-Application-Category-Labeling-Challenge/data/submit/baseline_' + 'lgb' + '.csv',\n",
    "        index=None,\n",
    "        encoding='utf8')\n",
    "\n",
    "\n",
    "def add_new_apptype_train_data(df, **params):\n",
    "    \"\"\"\n",
    "    实现将具备两个label的数据转化为两条记录\n",
    "    :param df: \n",
    "    :param params: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    df_new = df[df['label2'] != 0]\n",
    "    df_new['label1'] = df['label2']\n",
    "    # 合并数据\n",
    "    df = pd.concat([df, df_new], axis=0)\n",
    "    # label2列清空\n",
    "    df['label2'] = 0\n",
    "   \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Index(['id', 'conment'], dtype='object')\nIndex(['label_code', 'label'], dtype='object')\nIndex(['id', 'label', 'conment'], dtype='object')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 获取数据\n",
    "app_desc = get_app_desc()\n",
    "apptype_id_name = get_apptype_id_name()\n",
    "apptype_train = get_apptype_train()\n",
    "\n",
    "print(app_desc.columns)\n",
    "print(apptype_id_name.columns)\n",
    "print(apptype_train.columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1407 1\n1406 1\n1405 1\n1404 1\n1403 1\n1402 1\n1401 1\n1408 1\n1409 1\n1410 1\n1411 1\n1426 1\n1425 1\n1424 1\n1423 1\n1422 1\n1421 1\n1420 1\n1419 1\n1418 1\n1417 1\n1415 1\n1414 1\n1413 1\n1412 1\n1427 1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for key, value in apptype_id_name['label_code'].value_counts().items():\n",
    "    if len(str(key)) == 4:\n",
    "        print(key, value)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "140901           4999\n140206           2350\n141001           1130\n142103            922\n140701            918\n                 ... \n140202|140211       1\n140702|142402       1\n141502|140901       1\n141401|142301       1\n140207|140201       1\nName: label, Length: 733, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "# 获取label1/label2特征列\n",
    "apptype_train['label'].value_counts()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(30000, 3)\nIndex(['id', 'label', 'conment'], dtype='object')\n{'1401': ['便捷生活', '打车', '地图导航', '免费WIFI', '租车', '代驾', '同城服务', '快递物流', '婚庆', '家政', '宠物', '公共交通', '政务', '社区服务', '薅羊毛'], '1402': ['游戏', '魔幻', '仙侠', '卡牌', '飞行空战', '射击游戏', '休闲益智', '动作类', '音乐', '体育竞技', '棋牌中心', '经营养成', '策略', 'MOBA', '辅助工具'], '1403': ['通讯社交', '约会社交', '即时通讯', '工作社交', '论坛圈子', '婚恋社交', '情侣社交', '社交工具', '生活社交'], '1404': ['阅读', '微博博客', '新闻', '漫画', '小说', '技术', '教辅', '问答交流', '搞笑', '杂志', '百科', '影视娱乐'], '1405': ['工作求职', '求职', '兼职'], '1406': ['影音娱乐', '视频', '短视频', '音乐', '直播', '电台', 'K歌', '成人'], '1407': ['教育', '中小学', '职考', '公务员', '英语', '视频教育', '高等教育', '成人教育', '艺术', '语言(非英语)'], '1408': ['出行旅游', '旅游资讯', '综合预定', '民航', '铁路', '船运', '酒店', '行程管理', '民宿短租', '出国'], '1409': ['工具'], '1410': ['亲子儿童'], '1411': ['母婴'], '1412': ['汽车', '驾校', '违章', '汽车咨询', '汽车交易', '日常养车', '行车辅助'], '1413': ['房产', '租房', '买房', '装修家居'], '1414': ['电子产品'], '1415': ['医疗健康', '问诊挂号', '养生保健', '医疗服务'], '1417': ['美容', '减肥瘦身', '美妆美业', '医美'], '1418': ['美食', '菜谱', '餐饮店'], '1419': ['体育运动', '体育咨讯', '运动健身'], '1420': ['支付'], '1421': ['金融理财', '保险', '股票', '借贷', '理财', '彩票', '记账', '银行'], '1422': ['美图摄影', '美颜', '影像剪辑', '摄影修图', '相机', '绘画'], '1423': ['购物', '二手', '电商', '团购', '外卖', '电影票务', '点评', '社区超市', '购物咨询', '租赁'], '1424': ['日常办公', '笔记', '办公', '日程管理'], '1425': ['女性'], '1426': ['商家', '经营', '收款'], '1427': ['其他']}\n30000\n1\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: \n.ix is deprecated. Please use\n.loc for label based indexing or\n.iloc for positional indexing\n\nSee the documentation here:\nhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: \n.ix is deprecated. Please use\n.loc for label based indexing or\n.iloc for positional indexing\n\nSee the documentation here:\nhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (53, '1409')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2892\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2893\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (53, '1409')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-081447546c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeal_label_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapptype_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapptype_id_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-081447546c48>\u001b[0m in \u001b[0;36mdeal_label_code\u001b[0;34m(df, apptype_id_name, **params)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mcounts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mconment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# 赋值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3543\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3544\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3545\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3547\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3382\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     def reindex_axis(\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1910\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m         merged_blocks = _merge_blocks(\n\u001b[0;32m-> 1912\u001b[0;31m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_can_consolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1913\u001b[0m         )\n\u001b[1;32m   1914\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   3316\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "print(apptype_train.shape)\n",
    "print(apptype_train.columns)\n",
    "\n",
    "\n",
    "def get_classification(df, **params):\n",
    "    \"\"\"\n",
    "    返回 类别\n",
    "    :param df: \n",
    "    :param params: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    \n",
    "    # 寻找大类的类别编号\n",
    "    for index in range(df.shape[0]):\n",
    "        key = df.ix[index, 'label_code']\n",
    "        value = df.ix[index, 'label']\n",
    "        \n",
    "        # 处理大类\n",
    "        if len(str(key)) == 4:\n",
    "            result[str(key)] = [value] \n",
    "        # 处理小类\n",
    "        else:\n",
    "            # 获取前4个字符\n",
    "            key_4 = str(key)[:4]\n",
    "            # 如果小类属于的大类已经在结果中\n",
    "            if key_4 in result.keys():\n",
    "                # 如果小类对应的值未存在结果中\n",
    "                if value not in result[key_4]:\n",
    "                    # 添加\n",
    "                    result[key_4].append(value)\n",
    "            # 如果小类属于的大类未包含在结果中\n",
    "            else:\n",
    "                result[key_4] = [value]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def deal_label_code(df, apptype_id_name, **params):\n",
    "    \"\"\"\n",
    "    处理label_code\n",
    "    :param df: \n",
    "    :param apptype_id_name: \n",
    "    :param params: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix\n",
    "    import numpy as np\n",
    "    \n",
    "    assert list(df.columns) == ['id', 'conment']\n",
    "    \n",
    "    classification = get_classification(apptype_id_name)\n",
    "    print(classification)\n",
    "    \n",
    "    print(df.shape[0])\n",
    "    \n",
    "    conments = df['conment']\n",
    "    keys = classification.keys()\n",
    "    for index in range(df.shape[0]):\n",
    "        if index % 10000 == 1:\n",
    "            print(index)\n",
    "            \n",
    "        # 获取内容\n",
    "        conment = conments[index]\n",
    "        \n",
    "        for column in keys:\n",
    "            # 计算出现次数\n",
    "            counts = 0\n",
    "            # 取label_code 对应的label\n",
    "            for label in classification[column]:\n",
    "                counts += conment.count(label)\n",
    "            # 赋值\n",
    "            df[index, column] = counts\n",
    "        \n",
    "    if 'id' in list(df.columns):\n",
    "        del df['id']\n",
    "    \n",
    "    # 标准化\n",
    "    df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))            \n",
    "    return csr_matrix(df.values)\n",
    "\n",
    "tmp = deal_label_code(apptype_train[['id', 'conment']], apptype_id_name)\n",
    "\n",
    "print(tmp.shape)\n",
    "print(tmp.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-e50da876",
   "language": "python",
   "display_name": "PyCharm (ForecastScore)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}